{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TvsJSeOzMNM"
   },
   "source": [
    "# Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUnLbI8fLkUK"
   },
   "source": [
    "## Recolección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAPlKonvL1ST"
   },
   "source": [
    "Importamos librerías necesarias durante le desarrollo del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0BVO7X2LmiK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import random as rd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJFDR0vsL4U3"
   },
   "source": [
    "Accedemos a la carpeta de drive donde se encuentra la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rmK49Z5MB2w",
    "outputId": "6ee5590d-e845-4f82-95d2-385488c3f4ae"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5EHB0DXBT5_"
   },
   "source": [
    "Cargamos la base de datos Drugs ABCXY, dentro de la variable 'DB'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bn2Vi6KNAVd"
   },
   "outputs": [],
   "source": [
    "DB = pd.read_csv('/content/drive/MyDrive/ML_TSIV/Decision_Tree/Drugs ABCXY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjCpS_Mn7G8y"
   },
   "source": [
    "Dejamos estática la base de datos sin modificar procesos posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSFKtvb87D8w"
   },
   "outputs": [],
   "source": [
    "DB_STAY = DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WtY37L6Be50"
   },
   "source": [
    "Damos un primer vistazo a la base de datos, mostrando los datos organizados en una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OP2_fUdoNFFf",
    "outputId": "ce99aba8-2f0e-4f45-f562-28ff8672ab85"
   },
   "outputs": [],
   "source": [
    "DB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bM_iQykiClUL"
   },
   "source": [
    "Función para transformar cada atributo cualitativo dentro de la base de datos a datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2QZIBH5w8XN"
   },
   "outputs": [],
   "source": [
    "def Cualit2Num(DBCN):\n",
    "  Titles = list(DBCN.columns)\n",
    "\n",
    "  Titles_str = []\n",
    "  for title in Titles:\n",
    "    if type(DBCN[title][0]) == str:\n",
    "      Titles_str.append(title)\n",
    "\n",
    "  for title in Titles_str:\n",
    "    types = pd.unique(DBCN[title])\n",
    "    i = 0\n",
    "    for data in types:\n",
    "      data_loc = np.where(DBCN[title] == data)[0]\n",
    "      for pos in data_loc:\n",
    "        DBCN[title][pos] = i\n",
    "      i += 1\n",
    "  return(DBCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwBxbQDqDovz"
   },
   "source": [
    "Llamamos a la función 'Cualit2Num' anterior para transformar la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "V-mH6srXDBIS",
    "outputId": "68854bd6-3f14-41fa-fa23-4133343126b6"
   },
   "outputs": [],
   "source": [
    "DB = Cualit2Num(DB)\n",
    "DB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LA7W5QYL96e"
   },
   "source": [
    "Posteriormente, desplegamos una representación gráfica de los datos, generando las relaciones entre cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "xaGjety8OP4d",
    "outputId": "968b08e8-23cc-47b2-a89c-fb9bbe25687b"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(DB, vars = DB.columns[1:6], hue = DB.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM4ylLHDPd-B"
   },
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onSwrv4lo45b"
   },
   "source": [
    "### Analizamos los datos de forma elemental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKsTrE-akX9V"
   },
   "source": [
    "Calculamos la cantidad de Atributos e Instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRDuzQ7tdbCp"
   },
   "outputs": [],
   "source": [
    "NoAtributos = len(DB.T)\n",
    "NoInstancias = len(DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwthNkUjTqwW"
   },
   "source": [
    "Convertimos la base de datos en un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5SOgERUTW9p"
   },
   "outputs": [],
   "source": [
    "DBar = DB.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQclTs0lTkwc"
   },
   "source": [
    "Calculamos el máximo y mínimo de cada Atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwJsFVkrTkRj"
   },
   "outputs": [],
   "source": [
    "MaximoDeAtributos = []\n",
    "MinimoDeAtributos = []\n",
    "for idx in range(NoAtributos):\n",
    "  CaractMax = max(DBar.T[idx])\n",
    "  CaractMin = min(DBar.T[idx])\n",
    "  MaximoDeAtributos.append(CaractMax)\n",
    "  MinimoDeAtributos.append(CaractMin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGFP8cPBpFpQ"
   },
   "source": [
    "Calculamos el primer y tercer cuartil (Q1 y Q3, respectivamente), de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bo9by3bkpLXT"
   },
   "outputs": [],
   "source": [
    "Q1 = []\n",
    "Q3 = []\n",
    "for idx in range(NoAtributos):\n",
    "  if str(type(DBar[0][idx]))[8 : -2] != 'str':\n",
    "    atrib = DBar.T[idx].tolist()\n",
    "    atrib.sort()\n",
    "\n",
    "    NoCuartil1 = 0.25 * (NoInstancias + 1)\n",
    "    if str(type(NoCuartil1))[8 : -2] != 'int':\n",
    "      pos1 = round(NoCuartil1)\n",
    "      if pos1 < NoCuartil1:\n",
    "        pos2 = pos1 + 1\n",
    "      else:\n",
    "        pos2 = pos1 - 1\n",
    "      NoCuartil1 = round((pos1 + pos2) / 2)\n",
    "    Cuartil1 = atrib[NoCuartil1 + 1]\n",
    "    incremento = 1\n",
    "    while True:\n",
    "      if str(Cuartil1) == 'nan':\n",
    "          Cuartil1 = atrib[NoCuartil1]\n",
    "          NoCuartil1 -= 1\n",
    "      else:\n",
    "        break\n",
    "\n",
    "    NoCuartil3 = 0.7 * (NoInstancias + 1)\n",
    "    if str(type(NoCuartil3))[8 : -2] != 'int':\n",
    "      pos1 = round(NoCuartil3)\n",
    "      if pos1 < NoCuartil3:\n",
    "        pos2 = pos1 + 1\n",
    "      else:\n",
    "        pos2 = pos1 - 1\n",
    "      NoCuartil3 = round((pos1 + pos2) / 2)\n",
    "    Cuartil3 = atrib[NoCuartil3 + 1]\n",
    "    while True:\n",
    "      if str(Cuartil3) == 'nan':\n",
    "          Cuartil3 = atrib[NoCuartil3]\n",
    "          NoCuartil3 -= 1\n",
    "      else:\n",
    "        break\n",
    "\n",
    "  Q1.append(Cuartil1)\n",
    "  Q3.append(Cuartil3)\n",
    "Q1 = np.array(Q1)\n",
    "Q3 = np.array(Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-SAYyUhotJo"
   },
   "source": [
    "### Detectamos outliers y eliminamos sus respectivas instancias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAMGX4eYrfvP"
   },
   "source": [
    "Calculamos el rango intercuantílico de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOetzPrHrKmL"
   },
   "outputs": [],
   "source": [
    "IQR = []\n",
    "for idx in range(len(Q1)):\n",
    "  IQR.append(Q3[idx] - Q1[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr37VRS0vdkM"
   },
   "source": [
    "Buscamos valores atípicos y el atributo en el que se encuentra ese valor (Seleccionamos quitar solo outliers extremos con OutType = 3, o también leves con OutType = 1.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt84MZGIri7l"
   },
   "outputs": [],
   "source": [
    "OutType = 3\n",
    "\n",
    "Inst2Elim = []\n",
    "for idx, Atrib in enumerate(DBar.T):\n",
    "  probe1 = Q1[idx] - OutType * IQR[idx]\n",
    "  probe2 = Q3[idx] + OutType * IQR[idx]\n",
    "  for idx2, Val in enumerate(Atrib):\n",
    "    if ((Val < probe1) or (Val > probe2)) and (idx2 not in Inst2Elim):\n",
    "      Inst2Elim.append(idx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHuRTC8L6gCG"
   },
   "source": [
    "Generamos una nuevo array de datos eliminando las instancias que contienen algún outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FQEZT6B4Mao"
   },
   "outputs": [],
   "source": [
    "DBWO = []\n",
    "for InstNum in range(len(DBar)):\n",
    "  if InstNum not in Inst2Elim:\n",
    "    DBWO.append(DBar[InstNum])\n",
    "\n",
    "DBWOar = np.array(DBWO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WoGwRSf6yRb"
   },
   "source": [
    "Desplegamos los valores sin outliers, los cuales fueron identificados considerando el rango intercuartílico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hm85XryKZydn",
    "outputId": "3054a8ca-56f0-4987-9e5f-1554d11986e4"
   },
   "outputs": [],
   "source": [
    "showDB = pd.DataFrame(DBWOar)\n",
    "sns.pairplot(showDB, vars = showDB.columns[1:6], hue = showDB.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBdx-w4Coovw"
   },
   "source": [
    "### Normalizamos los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwBgq2TtPiFF"
   },
   "source": [
    "Elegimos un rango de normalización entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09vLi9W1Twhn"
   },
   "outputs": [],
   "source": [
    "MaximoNormalizado = 1\n",
    "MinimoNormalizado = 0\n",
    "RangoNormalizado = MaximoNormalizado - MinimoNormalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9ZoFhCjT7xG"
   },
   "source": [
    "Normalizamos los valores y obtenemos el nuevo arreglo de valores normalizados 'DBNar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2KxJ6SmPqli"
   },
   "outputs": [],
   "source": [
    "DBNorm = []\n",
    "for idx in range(NoAtributos):\n",
    "  \n",
    "  CaractNorm = []\n",
    "  if str(type(DBWOar[0][idx]))[8 : -2] != 'str':\n",
    "    \n",
    "    RangodeDatos = MaximoDeAtributos[idx] - MinimoDeAtributos[idx]\n",
    "    for idx2 in range(NoInstancias):\n",
    "\n",
    "      if str(DBWOar[idx2][idx]) != 'nan':\n",
    "        D = DBWOar[idx2][idx] - MinimoDeAtributos[idx]\n",
    "        DPct = D / RangodeDatos\n",
    "        dNorm = RangoNormalizado * DPct\n",
    "        Normalizado = MinimoNormalizado + dNorm\n",
    "        CaractNorm.append(Normalizado)\n",
    "      else:\n",
    "        CaractNorm.append(DBWOar[idx2][idx])\n",
    "  \n",
    "  else:\n",
    "    for idx2 in range(NoInstancias):\n",
    "      CaractNorm.append(DBWOar[idx2][idx])\n",
    "  \n",
    "  DBNorm.append(CaractNorm)\n",
    "\n",
    "DBNar = np.array(DBNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLPfiMAsRjz3"
   },
   "source": [
    "Visualizamos una parte de la base de datos con los valores normalizados, para garantizar una correcta transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Brejl8imU4r7",
    "outputId": "da5d1c3a-2ccf-4be5-c37f-d1b2e2dca208"
   },
   "outputs": [],
   "source": [
    "DBNarT = DBNar.T\n",
    "showDB = pd.DataFrame(DBNarT)\n",
    "showDB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTpPPDKh791N"
   },
   "source": [
    "## Análisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuKGMuFLUBE1"
   },
   "source": [
    "### Serie de funciones creadas para obtener las métricas de rendimiento de un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGvrfvYiT5VU"
   },
   "outputs": [],
   "source": [
    "#Función para obtener el error cuadrático medio, recibe las listas de los valores predichos y los valores reales.\n",
    "def MSE(MSEpred, MSEreal):\n",
    "  MSEpredN = []\n",
    "  for MSEp in MSEpred:\n",
    "    MSEpredN.append(MSEp/100)\n",
    "\n",
    "  MSErealN = []\n",
    "  for MSEr in MSEreal:\n",
    "    MSErealN.append(MSEr/100)\n",
    "  \n",
    "  MSEsize = len(MSErealN)\n",
    "  MSEt = 0\n",
    "  for MSEidx in range(MSEsize):\n",
    "    MSEt += (MSEpredN[MSEidx] - MSErealN[MSEidx])**2\n",
    "  MSEf = MSEt / MSEsize\n",
    "  return(MSEf)\n",
    "\n",
    "#Función para calcular la tasa de clasificación, recibe las listas de los valores predichos y los valores reales.\n",
    "def TC(TCpred, TCreal):\n",
    "  TCsize = len(TCpred)\n",
    "  TCt = 0\n",
    "  for TCidx in range(TCsize):\n",
    "    if TCpred[TCidx] != TCreal[TCidx]:\n",
    "      TCt += 1\n",
    "  TCf = 1 - TCt / TCsize\n",
    "  return(TCf)\n",
    "\n",
    "#Función que obtiene los valores de la matriz de confusión (TP, FN, FP, TN), recibe las listas de los valores predichos y los valores reales.\n",
    "def calculo_error(confusion_matrix):\n",
    "  FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "  FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "  TP = np.diag(confusion_matrix)\n",
    "  TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "  FP = min(FP)\n",
    "  FN = min(FN)\n",
    "  TP = min(TP)\n",
    "  TN = min(TN)\n",
    "  return (TP, FN, FP, TN)\n",
    "\n",
    "#Funciones para calcular la tasa de clasificación (TdC), incluyendo la exactitud (TdCExact), precisión (TdCPre), sensitividad o Recall (TdCSens)\n",
    "#y puntaje F - beta con beta = 1, es decir, F1 (TdCF1).\n",
    "def TdC(TdCTP, TdCFN, TdCFP, TdCTN):\n",
    "  TdCExact = (TdCTP + TdCTN) / (TdCTP + TdCTN + TdCFP + TdCFN)\n",
    "  TdCPre = TdCTP / (TdCTP + TdCFP)\n",
    "  TdCSens = TdCTP / (TdCTP + TdCFN)\n",
    "  TdCF1 = (2 * TdCTP) / (2 * TdCTP + TdCFP + TdCFN)\n",
    "  return([TdCExact, TdCPre, TdCSens, TdCF1])\n",
    "\n",
    "#Función para obtener las estadísticas de rendimiento, recibe las listas de los valores predichos y los valores reales.\n",
    "def Estadisticas(EYPred, EYreal):\n",
    "  EMSE = MSE(EYPred, EYreal)\n",
    "  ETC = TC(EYPred, EYreal)\n",
    "  CM = confusion_matrix(EYPred, EYreal)\n",
    "  ETP, EFN, EFP, ETN = calculo_error(CM)\n",
    "  EExact, EPrecis, ESens, EF1 = TdC(ETP, EFN, EFP, ETN)\n",
    "  Estadistica = [EMSE, ETC, EExact, EPrecis, ESens, EF1]\n",
    "  return(Estadistica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlfcnVhf-Z6g"
   },
   "source": [
    "### Creación de una clase propia, la cual fungirá como un árbol de decisión usando el algoritmo de ID3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuH61h-6DQah"
   },
   "outputs": [],
   "source": [
    "class DecisionTree_ID3():\n",
    "  def Entropia(self, YE):\n",
    "    YE = list(YE)\n",
    "    TotalE = len(YE)\n",
    "    TiposE = np.unique(YE)\n",
    "    ET = 0\n",
    "    for TipoE in TiposE:\n",
    "      PEi = YE.count(TipoE) / TotalE\n",
    "      ET -= PEi * mt.log2(PEi)\n",
    "    return(ET)\n",
    "\n",
    "  def Ganancia(self, EG, AtributoG, YG):\n",
    "    AtributoGarr = AtributoG\n",
    "    AtributoG = list(AtributoG)\n",
    "    TotalG = len(AtributoG)\n",
    "    TiposG = np.unique(AtributoG)\n",
    "    GT = EG\n",
    "    for TipoG in TiposG:\n",
    "      posG = np.where(AtributoGarr == TipoG)[0]\n",
    "      posG = np.unique(posG)\n",
    "      YGSel = []\n",
    "      for pG in posG:\n",
    "        YGSel.append(YG[pG])\n",
    "      PGi = AtributoG.count(TipoG) / TotalG\n",
    "      GT -= PGi * self.Entropia(YGSel)\n",
    "    return(GT)\n",
    "\n",
    "  def PRN(self, XRN, YRN):\n",
    "    SRN = self.Entropia(YRN)\n",
    "    GananciasRN = []\n",
    "    XRN = np.array(XRN)\n",
    "    for AtributoRN in XRN.T:\n",
    "      GananciasRN.append(self.Ganancia(SRN, AtributoRN, YRN))\n",
    "    Rmax = max(GananciasRN)\n",
    "    GananciasRN = np.array(GananciasRN)\n",
    "    PosR = np.where(GananciasRN == Rmax)[0][0]\n",
    "    return(PosR)\n",
    "\n",
    "  def FDataNRes(self, XFDNR, YFDNR, RootPosFDNR, RootFDNR, LeafsFDNR):#, YGFR):\n",
    "    XFDNRarr = np.array(XFDNR)\n",
    "    XnewFDNR =  []\n",
    "    for idxFDNR, AtribFDNR in enumerate(XFDNRarr.T):\n",
    "      if idxFDNR != RootPosFDNR:\n",
    "        AtribFDNR = list(AtribFDNR)\n",
    "        XnewFDNR.append(AtribFDNR)\n",
    "    XnewFDNR = np.array(XnewFDNR).T\n",
    "    XnewFDNR = XnewFDNR.tolist()\n",
    "\n",
    "    XOutFDNR = []\n",
    "    YOutFDNR = []\n",
    "    if len(XnewFDNR) != 0:\n",
    "      for LeafFDNR in LeafsFDNR:\n",
    "        PosLeaf = np.where(RootFDNR == LeafFDNR)[0]\n",
    "        X2Add = []\n",
    "        Y2Add = []\n",
    "        for idxFDNR in PosLeaf:\n",
    "          X2Add.append(XnewFDNR[idxFDNR])\n",
    "          Y2Add.append(YFDNR[idxFDNR])\n",
    "        XOutFDNR.append(X2Add)\n",
    "        YOutFDNR.append(Y2Add)\n",
    "\n",
    "    LeafResFDNR = []\n",
    "    LeafStatusFDNR = []\n",
    "    for YLeafFDNR in YOutFDNR:\n",
    "      CounterFDNR = Counter(YLeafFDNR)\n",
    "      FirstFR  = CounterFDNR.most_common(1)\n",
    "      LeafResFDNR.append(FirstFR[0][0])\n",
    "\n",
    "      if len(np.unique(YLeafFDNR)) == 1:\n",
    "        LeafStatusFDNR.append(1)\n",
    "      else:\n",
    "        LeafStatusFDNR.append(0)\n",
    "    return(XOutFDNR, YOutFDNR, LeafResFDNR, LeafStatusFDNR)\n",
    "\n",
    "  def FindRoot(self, XFR, YFR):\n",
    "    RootPosFR = self.PRN(XFR, YFR)\n",
    "    XFRarr = np.array(XFR)\n",
    "    Root = XFRarr.T[RootPosFR]\n",
    "    LeafsFR = np.unique(Root)\n",
    "    DataNRes = self.FDataNRes(XFR, YFR, RootPosFR, Root, LeafsFR)#, YGFR)\n",
    "    Data4LeafXFR = DataNRes[0]\n",
    "    Data4LeafYFR = DataNRes[1]\n",
    "    LeafsResultsFR = DataNRes[2]\n",
    "    LeafsStatusFR = DataNRes[3]\n",
    "    return(RootPosFR, LeafsFR, Data4LeafXFR, Data4LeafYFR, LeafsResultsFR, LeafsStatusFR)\n",
    "\n",
    "  def PredDato(self, XPD, DTPD):\n",
    "    ProfundidadPD = 0\n",
    "    RootPD = XPD[DTPD[0][ProfundidadPD][0]]\n",
    "    LeafsPD = DTPD[1][ProfundidadPD]\n",
    "    NextPosPD = np.where(LeafsPD == RootPD)[0][0]\n",
    "    Ypred = DTPD[4][ProfundidadPD][NextPosPD]\n",
    "    while (DTPD[5][ProfundidadPD][NextPosPD] != 1):\n",
    "      try:\n",
    "        ProfundidadPD += 1\n",
    "        RootPD = XPD[DTPD[0][ProfundidadPD][NextPosPD]]\n",
    "        LeafsPD = DTPD[1][ProfundidadPD][NextPosPD]\n",
    "        NextPosPD = np.where(LeafsPD == RootPD)[0][0]\n",
    "        Ypred = DTPD[4][ProfundidadPD][NextPosPD]\n",
    "      except:\n",
    "        break\n",
    "    return(Ypred)\n",
    "\n",
    "  def fit(self, Xtrainfit, Ytrainfit):\n",
    "    AtribQuantity = len(Xtrainfit.T)\n",
    "    RootRes = self.FindRoot(Xtrainfit, Ytrainfit)\n",
    "    RootPos = RootRes[0]\n",
    "    Leafs = RootRes[1]\n",
    "    Data4LeafX = RootRes[2]\n",
    "    Data4LeafY = RootRes[3]\n",
    "    LeafsResults = RootRes[4]\n",
    "    LeafsStatus = RootRes[5]\n",
    "    FinalStatus = len(np.unique(LeafsStatus))\n",
    "    UsedAtrib = 1\n",
    "    self.Profundidad = 0\n",
    "    self.DT = [[[RootPos]], [Leafs], [Data4LeafX], [Data4LeafY], [LeafsResults], [LeafsStatus]]\n",
    "    while (UsedAtrib != AtribQuantity) and (FinalStatus != 1):\n",
    "      self.Profundidad += 1\n",
    "      self.DT[0].append([])\n",
    "      for idx, Root in enumerate(self.DT[1][self.Profundidad-1]):\n",
    "        Xtemp = self.DT[2][self.Profundidad-1][idx]\n",
    "        Ytemp = self.DT[3][self.Profundidad-1][idx]\n",
    "        if self.DT[5][self.Profundidad-1][idx] != 1: \n",
    "          RootRes = self.FindRoot(Xtemp, Ytemp)\n",
    "          RootPos = RootRes[0]\n",
    "          Leafs = RootRes[1]\n",
    "          Data4LeafX = RootRes[2]\n",
    "          Data4LeafY = RootRes[3]\n",
    "          LeafsResults = RootRes[4]\n",
    "          LeafsStatus = RootRes[5]\n",
    "          self.DT[0][self.Profundidad].append(RootPos)\n",
    "          self.DT[1].append(Leafs)\n",
    "          self.DT[2].append(Data4LeafX)\n",
    "          self.DT[3].append(Data4LeafY)\n",
    "          self.DT[4].append(LeafsResults)\n",
    "          self.DT[5].append(LeafsStatus)\n",
    "          UsedAtrib += 1\n",
    "      FinalStatus = len(np.unique(self.DT[5][self.Profundidad]))\n",
    "\n",
    "  def GetPred(self, Datos):\n",
    "    Ypred = []\n",
    "    for data in Datos:\n",
    "      Ypred.append(self.PredDato(data, self.DT))\n",
    "    return(Ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiRC_o30AA-h"
   },
   "source": [
    "## Entrenamos un modelo con el algoritmo de KNN generado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU6khg8Nb93W"
   },
   "source": [
    "### Generación de X e Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ailrcRRHb93X"
   },
   "source": [
    "Agregamos aleatoriedad al orden de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ar5tn4-Ob93Y"
   },
   "outputs": [],
   "source": [
    "RDBNar = rd.sample(DBNar.T.tolist(), k=len(DBNar.T))\n",
    "RDBNar = np.array(RDBNar).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6ZDWOlNb93Y"
   },
   "source": [
    "Seleccionamos el atributo para nuestro valor objetivo 'Y' y el resto 'X' como ejemplos para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMCww5h5b93Y"
   },
   "outputs": [],
   "source": [
    "X = DBNar[1:-2]\n",
    "X = X.T\n",
    "Y = DBNar[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svZqmla0VN-9"
   },
   "source": [
    "### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsz8dH_T5gXn"
   },
   "source": [
    "Haremos 5 pruebas, eligiendo K=5 para el método de K-FOLD, en este caso, 5-FOLD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7Fa4XjP50Sq"
   },
   "source": [
    "La base de datos ya se encuentra ordenada aletaoriamente, por lo tanto solo tomaremos distintas secciones para el 20% de pruebas y su respectivo 80% para netrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hrpx_vwgpbp"
   },
   "outputs": [],
   "source": [
    "Xres = X\n",
    "Yres = Y\n",
    "\n",
    "DBsize = len(Xres)\n",
    "DBp = DBsize / 5\n",
    "VDB = int(DBp)\n",
    "CDB = int(DBp * 2)\n",
    "SDB = int(DBp * 3)\n",
    "ODB = int(DBp * 4)\n",
    "\n",
    "Xtest1, Xtrain1, Ytest1, Ytrain1 = train_test_split(Xres, Yres, test_size = 0.80, shuffle = False)\n",
    "\n",
    "Xtrain2, Ytrain2 = Xres[:VDB].tolist() + Xres[CDB:].tolist(), Yres[:VDB].tolist() + Yres[CDB:].tolist()\n",
    "Xtrain2, Ytrain2 = np.array(Xtrain2), np.array(Ytrain2)\n",
    "Xtest2, Ytest2 = Xres[VDB:CDB], Yres[VDB:CDB]\n",
    "\n",
    "Xtrain3, Ytrain3 = Xres[:CDB].tolist() + Xres[SDB:].tolist(), Yres[:CDB].tolist() + Yres[SDB:].tolist()\n",
    "Xtrain3, Ytrain3 = np.array(Xtrain3), np.array(Ytrain3)\n",
    "Xtest3, Ytest3 = Xres[CDB:SDB], Yres[CDB:SDB]\n",
    "\n",
    "Xtrain4, Ytrain4 = Xres[:SDB].tolist() + Xres[ODB:].tolist(), Yres[:SDB].tolist() + Yres[ODB:].tolist()\n",
    "Xtrain4, Ytrain4 = np.array(Xtrain4), np.array(Ytrain4)\n",
    "Xtest4, Ytest4 = Xres[SDB:ODB], Yres[SDB:ODB]\n",
    "\n",
    "Xtrain5, Xtest5, Ytrain5, Ytest5 = train_test_split(Xres, Yres, test_size = 0.20, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YX-06H7i5F2"
   },
   "source": [
    "Entrenamos con KNN cada uno de los 5 grupos de datos\n",
    "Nota: Es posible elegir qué métrica ('MSE', 'TdC', 'Exactitud', 'Precision', 'Recall' o 'F1') tomar como referencia, en este caso se elige 'Precision'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6Nud9b0jIMp"
   },
   "outputs": [],
   "source": [
    "model1 = DecisionTree_ID3()\n",
    "model1.fit(Xtrain1, Ytrain1)\n",
    "\n",
    "model2 = DecisionTree_ID3()\n",
    "model2.fit(Xtrain2, Ytrain2)\n",
    "\n",
    "model3 = DecisionTree_ID3()\n",
    "model3.fit(Xtrain3, Ytrain3)\n",
    "\n",
    "model4 = DecisionTree_ID3()\n",
    "model4.fit(Xtrain4, Ytrain4)\n",
    "\n",
    "model5 = DecisionTree_ID3()\n",
    "model5.fit(Xtrain5, Ytrain5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNm15ibjn5GX"
   },
   "source": [
    "Determinamos las predicciones de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoydmrbyroLh"
   },
   "outputs": [],
   "source": [
    "Ymodel1Pred = model1.GetPred(Xtest1)\n",
    "TasCla1 = TC(Ymodel1Pred, Ytest1)\n",
    "\n",
    "Ymodel2Pred = model2.GetPred(Xtest2)\n",
    "TasCla2 = TC(Ymodel2Pred, Ytest2)\n",
    "\n",
    "Ymodel3Pred = model3.GetPred(Xtest3)\n",
    "TasCla3 = TC(Ymodel3Pred, Ytest3)\n",
    "\n",
    "Ymodel4Pred = model4.GetPred(Xtest4)\n",
    "TasCla4 = TC(Ymodel4Pred, Ytest4)\n",
    "\n",
    "Ymodel5Pred = model5.GetPred(Xtest5)\n",
    "TasCla5 = TC(Ymodel5Pred, Ytest5)\n",
    "\n",
    "StadisticFin = (TasCla1 + TasCla2 + TasCla3 + TasCla4 + TasCla5) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EJHOGwQ3sFW",
    "outputId": "6da851e3-b631-4b4f-ad56-6ec92de5be34"
   },
   "outputs": [],
   "source": [
    "print('Tasa de clasificación de la prueba 1 =', str(TasCla1) + '.')\n",
    "print('Tasa de clasificación de la prueba 2 =', str(TasCla2) + '.')\n",
    "print('Tasa de clasificación de la prueba 3 =', str(TasCla3) + '.')\n",
    "print('Tasa de clasificación de la prueba 4 =', str(TasCla4) + '.')\n",
    "print('Tasa de clasificación de la prueba 5 =', str(TasCla5) + '.')\n",
    "print('Precisión final =', str(StadisticFin) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd02o0SAALzW"
   },
   "source": [
    "## Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MezwzihAcLL"
   },
   "source": [
    "### Analizamos métricas de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZTA5n2ZzdwR"
   },
   "source": [
    "Tranformamos los datos de las etiquetas a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UUqpGTRtm4h",
    "outputId": "6086ec0d-e3e9-4b95-b47b-c1cd8e1f3640"
   },
   "outputs": [],
   "source": [
    "Yt1 = []\n",
    "for Ytt1 in Ytest1:\n",
    "  Yt1.append(int(Ytt1*100))\n",
    "\n",
    "Ytp1 = []\n",
    "for Yttp1 in Ymodel1Pred:\n",
    "  Ytp1.append(int(Yttp1*100))\n",
    "\n",
    "Ytp2 = []\n",
    "for Yttp2 in Ymodel2Pred:\n",
    "  Ytp2.append(int(Yttp2*100))\n",
    "\n",
    "Ytp3 = []\n",
    "for Yttp3 in Ymodel3Pred:\n",
    "  Ytp3.append(int(Yttp3*100))\n",
    "\n",
    "Ytp4 = []\n",
    "for Yttp4 in Ymodel4Pred:\n",
    "  Ytp4.append(int(Yttp4*100))\n",
    "\n",
    "Ytp5 = []\n",
    "for Yttp5 in Ymodel5Pred:\n",
    "  Ytp5.append(int(Yttp5*100))\n",
    "\n",
    "print(Yt1)\n",
    "print(Ytp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4bGLCj33ccp"
   },
   "source": [
    "Generamos la tabla de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "009H9RJn6mLD",
    "outputId": "314e8b87-7344-4a2a-9965-ea79c77e24b0"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "ModelStatistics = Estadisticas(Ytp1, Yt1)\n",
    "\n",
    "STable = [ ['MSE', str(ModelStatistics[0])],\n",
    "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
    "     ['Exactitud', str(ModelStatistics[2])],\n",
    "     ['Precisión', str(ModelStatistics[3])],\n",
    "     ['Recall', str(ModelStatistics[4])],\n",
    "     ['F1', str(ModelStatistics[5])] ]\n",
    "\n",
    "print(tabulate(STable, headers = ['Métrica modelo 1', 'Valor'], tablefmt=\"presto\"))\n",
    "\n",
    "ModelStatistics = Estadisticas(Ytp2, Yt1)\n",
    "\n",
    "STable = [ ['MSE', str(ModelStatistics[0])],\n",
    "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
    "     ['Exactitud', str(ModelStatistics[2])],\n",
    "     ['Precisión', str(ModelStatistics[3])],\n",
    "     ['Recall', str(ModelStatistics[4])],\n",
    "     ['F1', str(ModelStatistics[5])] ]\n",
    "\n",
    "print(tabulate(STable, headers = ['Métrica modelo 2', 'Valor'], tablefmt=\"presto\"))\n",
    "\n",
    "ModelStatistics = Estadisticas(Ytp3, Yt1)\n",
    "\n",
    "STable = [ ['MSE', str(ModelStatistics[0])],\n",
    "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
    "     ['Exactitud', str(ModelStatistics[2])],\n",
    "     ['Precisión', str(ModelStatistics[3])],\n",
    "     ['Recall', str(ModelStatistics[4])],\n",
    "     ['F1', str(ModelStatistics[5])] ]\n",
    "\n",
    "print(tabulate(STable, headers = ['Métrica modelo 3', 'Valor'], tablefmt=\"presto\"))\n",
    "\n",
    "ModelStatistics = Estadisticas(Ytp4, Yt1)\n",
    "\n",
    "STable = [ ['MSE', str(ModelStatistics[0])],\n",
    "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
    "     ['Exactitud', str(ModelStatistics[2])],\n",
    "     ['Precisión', str(ModelStatistics[3])],\n",
    "     ['Recall', str(ModelStatistics[4])],\n",
    "     ['F1', str(ModelStatistics[5])] ]\n",
    "\n",
    "print(tabulate(STable, headers = ['Métrica modelo 4', 'Valor'], tablefmt=\"presto\"))\n",
    "\n",
    "ModelStatistics = Estadisticas(Ytp5, Yt1)\n",
    "\n",
    "STable = [ ['MSE', str(ModelStatistics[0])],\n",
    "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
    "     ['Exactitud', str(ModelStatistics[2])],\n",
    "     ['Precisión', str(ModelStatistics[3])],\n",
    "     ['Recall', str(ModelStatistics[4])],\n",
    "     ['F1', str(ModelStatistics[5])] ]\n",
    "\n",
    "print(tabulate(STable, headers = ['Métrica modelo 5', 'Valor'], tablefmt=\"presto\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwE70cUS6IER"
   },
   "source": [
    "Obtenemos la matriz de confusión de los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JuLTOdVl14Id",
    "outputId": "6f0485c1-1f7f-421d-ed50-739399851437"
   },
   "outputs": [],
   "source": [
    "def confusionMatrix(y_data_test, y_pred_test, titleChart, columns):\n",
    "  cm = confusion_matrix(y_data_test, y_pred_test)\n",
    "  cm=pd.DataFrame(cm, index=columns, columns=columns)\n",
    "  plt.figure(figsize = (5,5))\n",
    "  plt.title(titleChart)\n",
    "  sns.heatmap(cm, annot = True,fmt=\"d\", cmap='Blues' ,annot_kws={\"size\": 12})\n",
    "  plt.show()\n",
    "\n",
    "print('Matriz de confusión de la prueba 1\\n')\n",
    "confusionMatrix(Ytp1, Yt1, 'Matriz de confusión', list(np.unique(DB_STAY['Drug'])))\n",
    "print('\\n\\nMatriz de confusión de la prueba 2\\n')\n",
    "confusionMatrix(Ytp2, Yt1, 'Matriz de confusión', list(np.unique(DB_STAY['Drug'])))\n",
    "print('\\n\\nMatriz de confusión de la prueba 3\\n')\n",
    "confusionMatrix(Ytp3, Yt1, 'Matriz de confusión', list(np.unique(DB_STAY['Drug'])))\n",
    "print('\\n\\nMatriz de confusión de la prueba 4\\n')\n",
    "confusionMatrix(Ytp4, Yt1, 'Matriz de confusión', list(np.unique(DB_STAY['Drug'])))\n",
    "print('\\n\\nMatriz de confusión de la prueba 5\\n')\n",
    "confusionMatrix(Ytp5, Yt1, 'Matriz de confusión', list(np.unique(DB_STAY['Drug'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOBqB2_0F_fF"
   },
   "source": [
    "Finalmente, usaremos el intervalo de confianza Z para obtener los valores entre los que se encontraría la tasa de clasificación global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8ZEJmcd6uMT",
    "outputId": "66d240cc-7da2-4d6b-c843-b7937641685c"
   },
   "outputs": [],
   "source": [
    "def media(Nums):\n",
    "  n = len(Nums)\n",
    "  Suma = 0\n",
    "  for Num in Nums:\n",
    "    Suma += Num\n",
    "  ResM = Suma/n\n",
    "  return(ResM)\n",
    "\n",
    "def DesvEst(Nums):\n",
    "  n = len(Nums)\n",
    "  med = media(Nums)\n",
    "  Suma = 0\n",
    "  for Num in Nums:\n",
    "    Suma += (Num - med)**2\n",
    "  ResDE = (Suma / n)**0.5\n",
    "  return(ResDE)\n",
    "\n",
    "Cant_Pruebas = 50\n",
    "TCs = []\n",
    "for n in range(Cant_Pruebas):\n",
    "  model = DecisionTree_ID3()\n",
    "  model.fit(Xtrain1, Ytrain1)\n",
    "  YmodelPred = model.GetPred(Xtest1)\n",
    "  TasCla = TC(YmodelPred, Ytest1)\n",
    "  TCs.append(TasCla)\n",
    "\n",
    "MediaTC = media(TCs)\n",
    "DesvEstTC = DesvEst(TCs)\n",
    "\n",
    "Z = 1.96\n",
    "\n",
    "RangoError = Z*(DesvEstTC/(Cant_Pruebas)**0.5)\n",
    "\n",
    "print('Elegimos un valor de Z = 1.96 para un intervalo de confianza de 95%, logrando así un valor global de tasa de clasifciacion =', str(round(MediaTC, 4)), ' y un intervalo de confianza de', str(RangoError) + '.')\n",
    "print('\\nLo anterior quiere decir, que el valor real de Tasa de clasificación está entre', str(MediaTC - RangoError), 'y', str(MediaTC + RangoError) + '.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DecisionTree_JIOG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
